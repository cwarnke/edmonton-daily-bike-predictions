{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e2da1c-23db-4538-9913-021b357b96e5",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The purpose of the notebook is to train a model that will predict the number of cyclist for a given location in Edmonton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa737a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas==1.5.3\n",
    "!pip install --upgrade numpy==1.24.3\n",
    "!pip install --upgrade matplotlib==3.7.1\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "pkg_resources.require(\"pandas==1.5.3\")\n",
    "pkg_resources.require(\"numpy==1.24.3\")\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# This ensures plots are displayed inline in the Jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5809949f-c986-4aaf-a80b-73eb5e4c0c82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Collect Data\n",
    "\n",
    "Collection the data from Edmonton's data hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90322d-e91e-4a92-b56f-a498ec537f2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Collect daily forecast\n",
    "\n",
    "The *Speed of Maximum Wind Gust (km/h)* column from the data source has mixed data types. In the snippet below everything is cleaned and converted to a float. If the value cannot be converted to a float it is considered NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9baa87-b9cb-44a9-8775-57b57ccbf2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataFilePath = \"data/Weather_Data__Daily__-_Environment_Canada.csv\"\n",
    "cols = list(pandas.read_csv(dataFilePath, nrows=1))\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc9c6d-28bd-49f3-a7e6-009d28cb9033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edmontonWeatherStationName = [\"EDMONTON STONY PLAIN\"]\n",
    "\n",
    "cols = list(pandas.read_csv(dataFilePath, nrows=1))\n",
    "\n",
    "def speed_of_max_wind_gust(col):\n",
    "    if not isinstance(col, float):\n",
    "        return float('NaN')\n",
    "    else:        \n",
    "        return col\n",
    "    \n",
    "edmontonDailyWeather = pandas.read_csv(dataFilePath, converters={'Speed of Maximum Wind Gust (km/h)': speed_of_max_wind_gust})\n",
    "\n",
    "edmontonDailyWeather = edmontonDailyWeather[edmontonDailyWeather[\"Station Name\"].isin(edmontonWeatherStationName)]\n",
    "edmontonDailyWeather.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc46de-020a-40f2-89c0-131fe32e8108",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Collect daily cyclist count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766a5e0-6365-4dc0-b961-63ca944d911b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edmontonLocation = [\"100 Avenue E of 107 Street\"]\n",
    "\n",
    "edmontonBikeCounts = pandas.read_csv(\"data/Daily_Pedestrian_and_Bike_Counts.csv\")\n",
    "edmontonBikeCounts = edmontonBikeCounts[edmontonBikeCounts[\"Counter Location Description\"].isin(edmontonLocation)]\n",
    "edmontonBikeCounts['Year'] = pandas.DatetimeIndex(edmontonBikeCounts['Log Timstamp']).year\n",
    "edmontonBikeCounts['Month'] = pandas.DatetimeIndex(edmontonBikeCounts['Log Timstamp']).month\n",
    "edmontonBikeCounts['Day'] = pandas.DatetimeIndex(edmontonBikeCounts['Log Timstamp']).day\n",
    "edmontonBikeCounts.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46aadbd-7295-4d96-88a5-5a0414c9ff66",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize = (9,12))\n",
    "\n",
    "label = edmontonBikeCounts['Total Cyclist Count']\n",
    "\n",
    "# Plot the histogram   \n",
    "ax[0].hist(label, bins=100)\n",
    "ax[0].set_ylabel('Frequency')\n",
    "\n",
    "# Add lines for the mean, median, and mode\n",
    "ax[0].axvline(label.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
    "ax[0].axvline(label.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
    "\n",
    "# Plot the boxplot   \n",
    "ax[1].boxplot(label, vert=False)\n",
    "ax[1].set_xlabel('Total Cyclist Count')\n",
    "\n",
    "plt.autoscale()\n",
    "\n",
    "# Add a title to the Figure\n",
    "fig.suptitle('Total Cyclist Count Distribution for ' + edmontonLocation[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05c5f0-4c87-451f-9cde-3d03e29f03e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Join the weather & daily cyclist count\n",
    "\n",
    "Combine the weather and cyclists count datasets into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e407a-bde7-4def-a091-1fa8a9a756a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined = pandas.merge(edmontonDailyWeather, edmontonBikeCounts, on=[\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "numeric_features = ['Mean Temperature (C)', 'Total Rain (mm)', 'Total Snow (cm)']\n",
    "categorical_features = ['Month','Day']\n",
    "\n",
    "print(combined.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9194b1e-6d35-4690-974b-9505359c67b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explore the combined data\n",
    "\n",
    "Explore some data that we think will have an impact on the number of cyclists for any given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618448e0-4e90-4ba3-b204-05e2b3ab1dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_features = ['Mean Temperature (C)', 'Total Rain (mm)', 'Total Snow (cm)']\n",
    "\n",
    "# Plot a histogram for each numeric feature\n",
    "for col in numeric_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    feature = combined[col]\n",
    "    feature.hist(bins=100, ax = ax)\n",
    "    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
    "    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
    "    ax.set_title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c64e1f-78d5-4483-82d2-c462e15197a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in categorical_features:\n",
    "    counts = combined[col].value_counts().sort_index()\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    counts.plot.bar(ax = ax, color='steelblue')\n",
    "    ax.set_title(col + ' counts')\n",
    "    ax.set_xlabel(col) \n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6a5b2-9b64-4ff4-8411-f8073071c93a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in numeric_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    feature = combined[col]\n",
    "    label = combined['Total Cyclist Count']\n",
    "    correlation = feature.corr(label)\n",
    "    plt.scatter(x=feature, y=label)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Total Cyclist Count')\n",
    "    ax.set_title('Total Cyclist Count vs ' + col + '- correlation: ' + str(correlation))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb174bac-8e9e-432a-b0ed-416ebe67b8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot a boxplot for the label by each categorical feature\n",
    "for col in categorical_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    combined.boxplot(column = 'Total Cyclist Count', by = col, ax = ax)\n",
    "    ax.set_title('Label by ' + col)\n",
    "    ax.set_ylabel(\"Total Cyclist Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c254c",
   "metadata": {},
   "source": [
    "## Train the Model using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84047415",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow==2.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9670b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "pkg_resources.require(\"tensorflow==2.13.0\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101684c",
   "metadata": {},
   "source": [
    "### Combine cyclist and weather data\n",
    "\n",
    "Combine the cyclist and weather data together using the date. Once the data is combined, select only the feature and label columns. Feature columns are separated into numeric and categorical features. Numeric features will be normalized and cateforical features will be one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad642d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['MeanTemperature', 'TotalRain', 'TotalSnow']\n",
    "categorical_features = ['Month','Day']\n",
    "featureCols = ['MeanTemperature', 'TotalRain', 'TotalSnow', 'Month', 'Day']\n",
    "labelCol = 'TotalCyclistCount'\n",
    "allCols = featureCols\n",
    "allCols.append(labelCol)\n",
    "\n",
    "allOriginalCols = ['Mean Temperature (C)', 'Total Rain (mm)', 'Total Snow (cm)', 'Total Cyclist Count', 'Month', 'Day']\n",
    "\n",
    "combined = pandas.merge(edmontonDailyWeather, edmontonBikeCounts, on=[\"Year\", \"Month\", \"Day\"])\n",
    "combined = combined[allOriginalCols]\n",
    "\n",
    "combinedWithRenamedCols = combined.rename(columns={'Mean Temperature (C)': 'MeanTemperature', 'Total Rain (mm)': 'TotalRain', 'Total Snow (cm)':'TotalSnow', 'Total Cyclist Count': 'TotalCyclistCount'})\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = np.split(combinedWithRenamedCols.sample(frac=1), [int(0.8*len(combinedWithRenamedCols)), int(0.9*len(combinedWithRenamedCols))])\n",
    "\n",
    "print (combinedWithRenamedCols.head(10))\n",
    "print(len(train_dataset), 'training examples')\n",
    "print(len(val_dataset), 'validation examples')\n",
    "print(len(test_dataset), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebfa07",
   "metadata": {},
   "source": [
    "### Define a utility to convert a Pandas data frame to Tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ffee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to convert a data frame into a tf.data.Dataset, then shuffles and batches the data.\n",
    "def df_to_dataset(dataframe, labelCol, shuffle=True, batch_size=32):\n",
    "  df = dataframe.copy()\n",
    "  print (df.columns)\n",
    "  labels = df.pop(labelCol)\n",
    "  df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d114aaf6",
   "metadata": {},
   "source": [
    "### Convert Pandas data frames (training, test, and validation) to Tensorflow datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cac096",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train_dataset, labelCol, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test_dataset, labelCol, shuffle=False, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val_dataset, labelCol, shuffle=False, batch_size=batch_size)\n",
    "[(train_features, label_batch)] = train_ds.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4df20e",
   "metadata": {},
   "source": [
    "### Define feature wise layer functions\n",
    "\n",
    "The normalized layer function will create a normalization layer for a specific numeric feature. The category encoding function will create a category encoding layer for a speicific categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function that applies feature-wise normalization to numerical features.\n",
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for the feature.\n",
    "  normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields the feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a layer that turns strings into integer indices.\n",
    "  if dtype == 'string':\n",
    "    index = layers.StringLookup(max_tokens=max_tokens)\n",
    "  # Otherwise, create a layer that turns integer values into integer indices.\n",
    "  else:\n",
    "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Prepare a `tf.data.Dataset` that only yields the feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Encode the integer indices.\n",
    "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "  # Apply multi-hot encoding to the indices. The lambda function captures the\n",
    "  # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "  return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8778f",
   "metadata": {},
   "source": [
    "### Create model input tensors\n",
    "\n",
    "Create the inputs that will be used to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dde3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numerical features.\n",
    "for header in numeric_features:\n",
    "  numeric_col_input = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col_input)\n",
    "  all_inputs.append(numeric_col_input)\n",
    "  encoded_features.append(encoded_numeric_col)\n",
    "\n",
    "# Categorical features\n",
    "for header in categorical_features:\n",
    "  categorical_col_input = tf.keras.Input(shape=(1,), name=header, dtype='int32')\n",
    "  encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                               dataset=train_ds,\n",
    "                                               dtype='int32',\n",
    "                                               max_tokens=5)\n",
    "  encoded_categorical_col = encoding_layer(categorical_col_input)\n",
    "  all_inputs.append(categorical_col_input)\n",
    "  encoded_features.append(encoded_categorical_col)\n",
    "    \n",
    "print(\"Encoded Features:\")\n",
    "print(encoded_features)\n",
    "print(\"Inputs:\")\n",
    "print(all_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997cbe10",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1144230",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "              loss='mean_absolute_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd8b25",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b16e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=20, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4bd27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pandas.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Total Cyclists]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds)\n",
    "\n",
    "# Plot predicted vs actual based on the test dataset\n",
    "plt.scatter(test_dataset[labelCol], predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Cyclist Count Predictions')\n",
    "z = np.polyfit(test_dataset[labelCol], predictions, 1)\n",
    "p = np.poly1d([z[0][0],z[1][0]])\n",
    "plt.plot(test_dataset[labelCol],p(test_dataset[labelCol]), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f43bb",
   "metadata": {},
   "source": [
    "### Try it out\n",
    "\n",
    "Pass in some sample inputs to try the model out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724056fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleInput = {\n",
    "    'MeanTemperature': -22,\n",
    "    'TotalRain': 0,\n",
    "    'TotalSnow': 0,\n",
    "    'Month': 12,\n",
    "    'Day': 23\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sampleInput.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4dde5",
   "metadata": {},
   "source": [
    "### Save/Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('models/100-Avenue-E-of-107-Street-Model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
